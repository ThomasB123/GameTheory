\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage{braket, multirow, graphicx}
\usepackage{commath,amsmath,amssymb,amsfonts}
\usepackage[sorting=none]{biblatex}
\usepackage[left=0.5in,right=0.5in,top=0.5in,bottom=0.8in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{multicol}
\renewcommand*{\bibfont}{\small}
\renewcommand\thesection{\Roman{section}.}
\setlength\bibitemsep{0pt}
\addbibresource{bib.bib}

\begin{document}


\begin{center}
	\LARGE{Algorithmic Game Theory Assignment}\\[0.1cm]
	\Large{Group work Component}\\[0.1cm]
	Group 8\\[0.1cm]
\end{center}
\vspace{0.8cm}

\begin{multicols}{2}
\section{Introduction}
This paper is a report on the complexity of Nash equilibria, summarising the reductions and results of \cite{Daskalakis.2009} and \cite{Fabrikant.2004}. We first discuss the background and motivation of these complexities, and then the results discovered and proof methods used in \cite{Daskalakis.2009} and \cite{Fabrikant.2004}. Additional research of interest in similar areas is also deliberated.
\section{Relevant Background}
Game Theory is the study of agent behaviour in models of competition. Each player chooses an action, which determines the payoff both players receive \cite{OsborneMartinJ..2011}. A famous example of a game is the Prisoner’s Dilemma, which pits two prisoners against each other. A player’s strategy determines what the player should do, for example, should they keep quiet, or should they fink, and with what probability?

A Nash equilibrium is a set of strategies for each player such that each player does not want to change their given strategy, i.e. each player would be more likely to receive a lower payoff by deviating from their current strategy. These strategies can be separated into two categories: pure Nash equilibria that only includes strategies that say to go for just one action, and mixed Nash equilibria where an action is chosen based on a probability distribution \cite{OsborneMartinJ..2011}. The only pure Nash equilibria for the Prisoner’s Dilemma is for both players to fink, since if one of the players were to stay quiet instead, that player would spend longer in prison. An example of a mixed Nash equilibria is for the game rock-paper-scissors, where each player should play rock, paper, and scissors each with $\frac{1}{3}$ probability, since it maximises their expected payoff (which is 0) \cite{Daskalakis.2009}.

Nash’s Theorem states that all games with a finite number of players and pure strategies must have at least one Nash equilibrium; it does not matter whether it is pure, or mixed. This has been proven using the Fixed Point theorem, where if a ``best response" function is defined between a player’s current strategy and a unilaterally deviating strategy, it can be said that there is always a strategy S such that the best response is to stick with the strategy S \cite{NashJohnF..1950}.

Within the two main complexity classes of \textbf{\textsc{P}} and \textbf{\textsc{NP}} there exist many sub-classes. A problem is said to be complete within a class when all other problems in its class can be reduced (i.e., transformed) to it with an appropriate reduction. A problem is said to be total when, for every possible instance, there is guaranteed to be at least one solution. The problem then moves from asking if there is a correct solution, to finding a correct solution. The class of all such problems is called Total Function Non-deterministic Polynomial Search (\textbf{\textsc{tfnp}}) \cite{Wigderson.2019}. \textbf{\textsc{tfnp}} does not have any complete problems of its own, but sub-classes of it do.

One important subclass of \textbf{\textsc{tfnp}} is Polynomial Local Search (\textbf{\textsc{pls}}). A problem in \textbf{\textsc{pls}} can calculate the cost of a solution in polynomial time, along with exploring the neighbourhood of the solution in polynomial time. This makes it possible to verify a point is a local optima in polynomial time. A problem can be shown to be \textbf{\textsc{pls}}-complete if it can be reduced to \textsc{circuitflip} \cite{Borzechowski.19thSeptember2016}.

Another key subclass of \textbf{\textsc{tfnp}} is Polynomial Parity Arguments on Directed graphs (\textbf{\textsc{ppad}}). This class is defined in terms of its complete problems, with the main such problem being the \textsc{end of the line} problem. The \textsc{end of the line} problem works on a potentially exponentially large directed graph G that has no isolated vertices, and each vertex has at most one predecessor, and at most one successor. $G$ is defined by a function f that takes a vertex as an input and returns the predecessor and successor of a vertex, if they exist. The \textsc{end of the line} problem asks, given $G$ and a vertex $s$ that has a successor but no predecessor, find a $t \neq s$ with either no successor or predecessors \cite{PapadimitriouChristosH..}.



\section{Results}
This section summarises the findings of \cite{Daskalakis.2009} and \cite{Fabrikant.2004}.

Paper \cite{Daskalakis.2009} provides evidence that there are games in which convergence to a mixed Nash equilibrium takes prohibitively long. It also shows that finding a mixed Nash equilibrium is complete for a class of problems called \textbf{\textsc{ppad}}, containing several other known hard problems. The results reported in this article indicate that there is not an efficient algorithm for computing a mixed Nash equilibrium. The main result in \cite{Daskalakis.2009} is that the computational problem of finding mixed Nash equilibria (\textsc{nash}) is \textbf{\textsc{ppad}}-complete, and this is proven in two parts. First, that the problem is in \textbf{\textsc{ppad}}, meaning that it can be reduced to the \textsc{end of the line} problem which is a total search problem. The second part is to prove that the problem is complete, achieved by the reverse reduction (\textbf{\textsc{ppad}} back to \textsc{nash}). Both parts here are established through Brouwer's fixed point theorem. The results obtained in \cite{Daskalakis.2009} also imply that finding an $\varepsilon$-Nash equilibrium is \textbf{\textsc{ppad}}-complete, if $\varepsilon$ is inversely proportional to an exponential function of the game size. 

Paper \cite{Fabrikant.2004} shows that in congestion games a pure Nash equilibrium can be computed in polynomial time in the symmetric network case, while the problem is \textbf{\textsc{pls}}-complete in general. This overall result is proven in several stages. \cite{rosenthal1973class} shows that every congestion game has a pure Nash equilibrium. Second, \cite{Fabrikant.2004} proves that there is a polynomial algorithm for finding a pure Nash equilibrium in symmetric network congestion games. Third, it is shown that computing a Nash equilibrium in the general network case is \textbf{\textsc{pls}}-complete. \cite{Fabrikant.2004} then shows that under the necessary smoothness assumptions (delay functions satisfying the Lipschitz assumption with constant $K$), the $\varepsilon$-approximate Nash equilibria of non-atomic congestion games can be computed in strongly polynomial time. Where the non-atomic congestion game is the limit of the congestion game as $n$, the number of players, goes to infinity. This problem is reduced to the multicommodity min-cost flow problem in \cite{Fabrikant.2004}. Finally \cite{monderer1996potential} shows that any exact potential game is isomorphic to a congestion game, completing the overall result obtained by \cite{Fabrikant.2004}. 


\section{Reductions}
The first reduction described in \cite{Daskalakis.2009} is a reduction from \textsc{nash} to the \textsc{end of the line} problem given in \cite{Daskalakis.2009} in order to prove \textsc{nash} is in \textbf{\textsc{ppad}}. This reduction uses Brouwer's fixed point theorem, which put simply means that a mapping in the Euclidean space of a compact and convex subset back onto itself must have some fixed point that does not change in the mapping $F$. This gives rise to the problem \textsc{brouwer}, which is simply when given $F$ and any subset, find a fixed point. Two inconveniences are discussed in \cite{Daskalakis.2009} which are how to specify $F$ and how to deal with fixed points that are not rational numbers. These are solved by first restricting the subset to the unit cube and by assuming that $F$ is given by some tractable algorithm which can map from the unit cube to the correct value. To deal with irrational fixed points $F$ is assumed to obey a simple Lipschitz condition that simply means that the distance between result for 2 points is bounded by $K$ the Lipschitz constant of $F$ and distance between the 2 points. This is done so the domain can be discretized. As with \textsc{nash} this means approximate fixed points bounded by some constant $\epsilon$ can be found. A reduction exists from \textsc{brouwer} to \textsc{end of the line}\cite{Daskalakis.2009}. This is done by dividing the unit square into a mesh of small triangles (triangulation). The vertices of the triangles are coloured based on the angle $F$ maps it in from the horizontal. This 3-colouring satisfies a property that red cannot appear on the lower side of the square, blue cannot appear on the left side of the square, and the other 2 sides cannot have yellow. Sperner's Lemma states that any colouring obeying this property must have a triangle with all 3 colours. By the Lipschitz condition the vertices of such a triangle are fixed points. By having all triangles with a red and yellow vertex form a directed graph in which an edge exists from a triangle to another if they share an edge from red to yellow clockwise in the first triangle. Such a graph consists only of paths and cycles \cite{Daskalakis.2009}. An assumption can be made that the left of the square only has one edge between yellow and red. This edge is part of a triangle that may be 3-coloured or if not must form a path that ends at a 3-coloured triangle meaning at least one 3-coloured triangle must exist. This kind of graph is an instance of \textsc{end of the line}\cite{Daskalakis.2009}. \textsc{nash} can be trivially reduced to \textsc{brouwer} as a function can be defined that maps from the set of strategies to itself, based on payoff improvement. It is clear that a fixed point under such a function must correspond to a Nash equilibrium as there is no way to improve from it. Therefore this function and set of strategies form an instance of \textsc{brouwer}, consequently \textsc{nash} is reducible to \textsc{end of the line}.\par
To prove \textsc{nash} is \textbf{\textsc{ppad}}-complete \cite{Daskalakis.2009} presents a set of reductions from an instance of \textsc{end of the line} can be reduced to \textsc{nash}. First \textsc{end of the line} is reduced to \textsc{brouwer}; the unit cube is again used and it is subdivided into a mesh of smaller cubes (cubelets)  each with a grid point in its centre. These grid points can then be assigned 1 of 4 colours $[0-3]$ based on the vector $F(x)-x$. The vectors determining what colour is chosen are set so $F(x)-x$ is only near $0$ if $x$ is near all 4 colours. To convert an instance $G$ of \textsc{end of the line} to such a cube each vertex of the \textsc{end of the line} graph is placed either in bottom or top left edges of the cube. This gives rise to a special property that if an edge exists in $G$ between 2 vertices then a sequence of grid points will be coloured 1, 2, or 3. It is possible to create an arrangement of colours such that all 4 are only adjacent grid points (corresponding to an approximate fixed point) in an area of the cube that corresponds to a solution to \textsc{end of the line} and is thus \textbf{\textbf{\textsc{ppad}}}-complete.

Next by reducing \textsc{brouwer} to \textsc{nash} it can be shown \textsc{nash} is also \textbf{\textsc{ppad}}-complete. The reduction from \textsc{brouwer} to \textsc{end of the line} is such that all $F$s can be computed using circuits consisting of addition, multiplication, and comparison operators forming a dataflow graph \cite{Daskalakis.2009}. Each node of this graph can be converted into its own game which can then be composed with the other nodes games forming a larger game representing the full circuit result. Each of the mini games has 4 players $w$, $x$, $y$, $z$. Players can take either a ``go'' or ``stop'' action such that $z$'s action represents the result of performing the node operator on the probabilities of $x$ and $y$'s strategies, $w$ acts as a mediating node between $x$, $y$, and $z$ \cite{Daskalakis.2009}. Payoffs are then defined for the players such that, for multiplication, at any Nash equilibrium the probability $z$ picks ``go'' is the product of the $x$ and $y$ probabilities \cite{Daskalakis.2009}, payoffs can similarly be chosen for addition and multiplication by a constant. To represent a $F$ using this method, the location of a point $x$ in the unit cube can be represented by 3 players each choosing ``go'' with probability equal to the corresponding coordinate in the cube. Then by chaining together enough of the mini games described above $F$ can be calculated as the 3 output players whose ``go'' probabilities are the coordinates of $F(x)$. It is possible to assign suitable payoffs such that any Nash equilibrium results in the input players and output players having the same ``go'' probabilities which corresponds to a fixed point. In order to avoid contradicting Nash's theorem, $F$ must be calculated as the average of a grid around the point in the cube due to \textbf{the brittle comparator problem} \cite{Daskalakis.2009} giving an approximate fixed point. The game is, by construction, a graphical game \cite{Daskalakis.2009} and can be simulated as a three-player normal form game by having the 3 players represent $m$ nodes each that never play against each other in the dataflow graph or share a node that they both play against. Each of the players nodes don't compete with each other so there are no conflicts of interest, this means any Nash equilibrium in this 3 player game corresponds to one in the original game. A final necessary adjustment is to have the players compete in a rock-paper-scissors game to ensure the mixed-strategy profiles are balanced \cite{Daskalakis.2009}. The resulting 3 player game is efficient to compute and completes the reductions from \textsc{brouwer} to \textsc{nash} so \textsc{nash} is \textbf{\textsc{ppad}}-complete.
\par
The first result shown in \cite{Fabrikant.2004} is that a symmetric network potential game has a pure Nash equilibrium that can be found in polynomial time. This is done by reducing the network $N$ representing the game to an instance of \textsc{min-cost flow} by replacing all edges in $N$ with a set of parallel edges each with capacity 1 and costs given by the corresponding delay function for that edge (resource). It follows simply that any integer solution to this problem minimises the potential function $\phi(s)$ of $N$ \cite{Fabrikant.2004}. Next it is shown that finding pure Nash equilibria of all other types of congestion game is \textbf{\textsc{pls}}-complete. First it is proven for general congestion games by reducing a known \textbf{\textsc{pls}}-complete problem \textsc{posnae3flip} \cite{local_search_complex} to a general congestion game. Each 3-clause in an instance of \textsc{posnae3flip} can be represented as 2 resources, with no delay or delay equal to their weight if there are more than 2 players (variables in the formula). Each player has 2 strategies one contains all the first resource for clauses containing the player and the second contains all the second resource for those clauses. It is easy to see that a Nash equilibrium in such a game is an optimum of \textsc{posnae3flip}. Symmetric games are easily proven by reducing a non-symmetric game to one. This is done by adding a new resource to all states in each action set in the game. These new resources have delay functions such that $d_e(j)$ is a very large integer for all $j>1$ and $0$ otherwise. Any equilibrium to such a game must involve a player using one of these new action sets as a strategy. Due to the choice of delay function for the new resources it is obvious that such an equilibrium when the new resources are removed from the strategy is simply the same as an equilibrium in the original game.

Asymmetric network congestion games require a more complex route. The problem \textsc{posnae3flip} must be extended as new kinds of clauses are needed to express this case properly; previously acceptable clauses are now incompatible as this type of game is more specific \cite{Fabrikant.2004}. The new problem is called \textsc{witnessed xpnae3flip} and is constructed from \textsc{posnae3flip} as another proxy problem to make the proof possible. It is shown that there is a \textbf{\textsc{pls}} reduction from \textsc{witnessed xpnae3flip} to \textsc{network congestion game} by carefully creating edges in the network based on clauses in the instance of \textsc{xpnae3flip} and setting delays to reflect the properties of these clauses \cite{Fabrikant.2004}. It is further proved that \textsc{witnessed xpnae3flip} is also \textbf{\textsc{pls}}-complete. As \textsc{witnessed xpnae3flip} is constructed from \textsc{posnae3flip}, it is natural that this proof leverages the known \textbf{\textsc{pls}}-completeness of \textsc{posnae3flip} and so it follows similar steps to the reduction from \textsc{circuitflip} used in that original proof \cite{local_search_complex}.

\section{Related Research}
Papers \cite{Daskalakis.2009} and \cite{Fabrikant.2004} are far from the only research that has been conducted into the complexity of finding Nash equilibria in recent years. A number of these have focused on ``proper'' equilibria, which were first defined in \cite{MyersonR.B..1978}. Proper equilibria are essentially a subset of Nash equilibria, where for some small value $\varepsilon$, the probability assigned by a player to the worse of two mixed strategies is no greater than $\varepsilon$ times the probability they assign to playing the better one. One of these pieces of research is \cite{HansenKristofferArnsfelt.2018}, which shows that the problem of determining, given the payoff matrices, whether or not a given pure Nash Equilibrium for a 2-player game is a proper equilibrium is \textbf{\textsc{np}}-complete. This same paper also looks into the complexity of Polymatrix games, which are games where there are separate payoff matrices for each possible pair of players, and a player's payoff is the sum of their payoffs for each individual matrix that they feature in. This paper shows that for an $n$-player Polymatrix game, that the problem of calculating a proper equilibrium for such a game is in the \textbf{\textsc{ppad}} complexity class

Another variant of Nash Equilibria are relative $\varepsilon$-Nash Equilibria, which are strategy profiles where the incentive to deviate from that profile is no greater than some factor $\varepsilon$. One piece of research on this topic is found in \cite{Daskalakis.2013}, which shows that the problem of calculating a relative $\varepsilon$-Nash Equilibrium in a 2-player game is \textbf{\textsc{ppad}}-complete. Another piece of research in this field that did not focus on Proper Equilibria is found in \cite{rubinstein2016settling}, which proves that for any 2-player game, where each player has $n$ available actions, the problem of finding an $\varepsilon$-Nash equilibrium is in the \textbf{\textsc{ppad}} complexity class, and can be computed in quasi-polynomial time.

Research more directly related to \cite{Daskalakis.2009} and \cite{Fabrikant.2004} has also been made, for example \cite{Daskalakis.2015}, which at least partially answers a question posed at the end of \cite{Daskalakis.2009}, which asked whether or not there was a polynomial time algorithm to calculate approximate Nash equilibria. Paper \cite{Daskalakis.2015} finds that this is the case for any ``anonymous'' game, which is one where the payoff is not dependent on which other players perform various actions, only on how many do so, provided that the number of actions stays constant (i.e. it does not grow as the number of players increases).

Nash equlibiria are not the only solution concepts for games. Due to limited bandwidths on the Internet, it is desirable to use game theory to model the traffic on the Internet, with each user being represented by a selfish agent in the game (each user wants the quickest browser which will act to gain as much bandwidth as possible) \cite{friedman_learning_nodate}. A congestion game is the perfect setup for this, and as discussed already, the general case of finding a pure Nash equilibrium in such games is \textbf{\textsc{pls}}-complete. This complexity is unfortunate when aiming to use this in real-time to direct network traffic. There are also other issues with Nash equilibria in this setting which make finding an alternative worthwhile.

When there is limited information provided to the players of the game, Nash equilibria alone cannot completely capture the decision process agents must make \cite{friedman_learning_nodate, beyond_nash}. Source \cite{beyond_nash} presents a solution to this when the players are not aware of all the moves called an augmented game. This involves modelling the game in different ``views'' so that the unawareness can be captured. However, this is of limited use in the domain of Internet traffic; it becomes increasingly complex as more players and layers to the game build up, and it requires the viewpoint of an omniscient modeler, which would be computationally difficult to create in a distributed setting \cite{friedman_learning_nodate}. Another way to mitigate this issue is to abandon the traditional idea of a Nash Equilibrium entirely, and instead study the convergence behaviours of learning agents \cite{friedman_learning_nodate}. The simplest of these, called a ``stage learner'', learns in separate phases and plays the actions which had the highest average in the last phase with a higher probability in the current one. This key nondeterministic property allows the agent to be responsive to changes in the environment, which is vital for changing network traffic. Such learners are shown to have good convergence behaviour which leads to a new equilibrium notion as the convergence of a set of learners. More recently, this line of research has been joining with advances in reinforcement learning such as in \cite{nowe_game_2012}, and some researchers have even proposed computing Nash equilibria at every step to determine the optimal action strategy for learning agents \cite{lee_nash_2019}.

Nash equilibria can often give unfavourable solutions. As already outlined, a well-known instance of this is the Prisoners Dilemma. The only Nash equilibrium is for both players to fink, which results in a lower payoff for both players than cooperation. This was first conceptualised as Braess’ paradox \cite{braess_paradox_2005}, where adding more roads to a network can in fact slow the traffic flow. This kind of behaviour is extremely undesirable when attempting to improve the speed of network traffic. A strategy which can mitigate this is tit-for-tat, which improves the cooperability of agents in repeated games, which the transmission period of internet traffic can be modelled as. Here the agent starts out cooperating and then plays the action played by the other agent in subsequent stages \cite{beyond_nash}. However, this is not a Nash equilibrium unless the game is infinitely repeated. This is not true for any real-life game, so the Nash concept is not enough. Tit-for-tat was shown to be successful in Axelrod’s tournament \cite{alexrod}, and is even used as part of BitTorrent’s file sharing to optimise download speeds \cite{cohen_incentives_2003}. Therefore, it can be useful to analyse strategies which do not directly result in a Nash equilibrium.



\printbibliography
\end{multicols}
\end{document}
